{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\estimagic\\utilities.py:193: UserWarning: Standard matrix inversion failed due to LinAlgError described below. A pseudo inverse was calculated instead. Taking the inverse of the information matrix failed. Only ever use this covariance matrix or standard errors based on it for diagnostic purposes, not for drawing conclusions.\n",
      "  warnings.warn(header + msg)\n",
      "C:\\Anaconda\\anaconda3\\envs\\replication_ar2018\\lib\\site-packages\\estimagic\\inference\\shared.py:116: RuntimeWarning: invalid value encountered in sqrt\n",
      "  free[\"standard_error\"] = np.sqrt(np.diag(free_cov))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>p_value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.844</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betahat</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.010</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>1.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>2.145</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.141</td>\n",
       "      <td>2.150</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi</th>\n",
       "      <td>723.974</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.974</td>\n",
       "      <td>723.974</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>7.307</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.507</td>\n",
       "      <td>9.107</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>42.625</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.755</td>\n",
       "      <td>43.494</td>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  standard_error  p_value  ci_lower  ci_upper stars\n",
       "beta       0.835           0.005      0.0     0.826     0.844   ***\n",
       "betahat    0.999           0.006      0.0     0.988     1.010   ***\n",
       "delta      1.003             NaN      NaN       NaN       NaN   NaN\n",
       "gamma      2.145           0.002      0.0     2.141     2.150   ***\n",
       "phi      723.974           0.000      0.0   723.974   723.974   ***\n",
       "alpha      7.307           0.918      0.0     5.507     9.107   ***\n",
       "sigma     42.625           0.444      0.0    41.755    43.494   ***"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the two datasets and drop subjects whose individual estimates do not converge\n",
    "from src.config import SRC, BLD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from estimagic import estimate_ml\n",
    "\n",
    "data = pd.read_stata(SRC / \"original_data\" / \"decisions_data.dta\")    # full sample\n",
    "ind_keep = pd.read_csv(SRC / \"original_data\" / \"ind_to_keep.csv\")   # import csv with ID of subjects to keep \n",
    "data = data[data.wid.isin(ind_keep.wid_col1)] # this is the primary sample for the aggregate estimates (72 individuals)\n",
    "data = data[data.bonusoffered != 1]  # remove observations where a bonus was offered\n",
    "data[\"pb\"] = data[\"workdone1\"] / 10\n",
    "    # workdone1 can either be 10 or 0: dividing the variable by 10 creates the dummy\n",
    "data[\"ind_effort10\"] = (data[\"effort\"] == 10).astype(int)  # ind_effort10 dummy\n",
    "data[\"ind_effort110\"] = (data[\"effort\"] == 110).astype(int)  # ind_effort110 dummy\n",
    "data.index = np.arange(len(data.wid))\n",
    "\n",
    "\n",
    "def negloglike(params, data):\n",
    "    \n",
    "    \n",
    "    # We use np.array to allow for element-wise operations # make that piece of code better into one function\n",
    "    \n",
    "    \n",
    "    predchoice = ((params.loc[\"phi\", \"value\"]*(params.loc[\"delta\", \"value\"]**data[\"netdistance\"])*(params.loc[\"beta\", \"value\"]**data[\"today\"])*(params.loc[\"betahat\", \"value\"]**data[\"prediction\"])*data[\"wage\"])**(1/(params.loc[\"gamma\", \"value\"]-1)))-data[\"pb\"]*params.loc[\"alpha\", \"value\"]\n",
    "    \n",
    "    prob = (1-data[\"ind_effort10\"]-data[\"ind_effort110\"])*norm.pdf(data[\"effort\"], predchoice, params.loc[\"sigma\", \"value\"])+data[\"ind_effort10\"]*(1 - norm.cdf((predchoice-data[\"effort\"])/params.loc[\"sigma\", \"value\"]))+data[\"ind_effort110\"]*norm.cdf((predchoice-data[\"effort\"])/params.loc[\"sigma\", \"value\"])\n",
    "        \n",
    "    index_p0 = [i for i in range(0,len(prob)) if prob[i]==0] # vector containing the indexes when prob=0\n",
    "    index_p1 = [i for i in range(0,len(prob)) if prob[i]==1] # vector containing the indexes when prob=1\n",
    "    \n",
    "    # use a for loop to change the values   # change this to list comprehension\n",
    "    \n",
    "    for i in index_p0:\n",
    "        prob[i] = 1E-4\n",
    "        \n",
    "    for i in index_p1:\n",
    "        prob[i] = 1 - 1E-4\n",
    "    \n",
    "    contr = np.log(prob)\n",
    "    \n",
    "    return { \"contributions\": contr , \"value\": np.sum(contr)}\n",
    "\n",
    "\n",
    "def start_params():\n",
    "    \"\"\"\n",
    "    Define initial guesses Consistent with the ones used by Augenblick & Rabin in original paper\n",
    "    and Pozzi & unnari in their replication  \n",
    "\n",
    "    \"\"\"\n",
    "    parm =[0.8,1,1,2,500,7,40]\n",
    "    init_parm = pd.DataFrame(parm, columns = [\"value\"], index = [\"beta\", \"betahat\", \"delta\", \"gamma\", \"phi\", \"alpha\", \"sigma\"])\n",
    "    return init_parm\n",
    "\n",
    "def load_args():\n",
    "    netdistance = np.array(data[\"netdistance\"])\n",
    "    wage = np.array(data[\"wage\"])\n",
    "    today = np.array(data[\"today\"])\n",
    "    prediction = np.array(data[\"prediction\"])\n",
    "    pb = np.array(data[\"pb\"])\n",
    "    effort = np.array(data[\"effort\"])\n",
    "    ind_effort10 = np.array(data[\"ind_effort10\"])\n",
    "    ind_effort110 = np.array(data[\"ind_effort110\"])\n",
    "    return pd.DataFrame({\"netdistance\": netdistance, \"wage\":wage, \"today\": today , \"prediction\": prediction, \"pb\" : pb ,\"effort\": effort, \"ind_effort10\": ind_effort10,\"ind_effort110\": ind_effort110})\n",
    "\n",
    "params = start_params()\n",
    "data = load_args()\n",
    "\n",
    "\n",
    "\n",
    "res = estimate_ml(\n",
    "    loglike = negloglike,\n",
    "    params = start_params(),\n",
    "    optimize_options = {\"algorithm\": \"scipy_neldermead\"},\n",
    "    loglike_kwargs={\"data\": data}, \n",
    ")\n",
    "\n",
    "res[\"summary_jacobian\"].round(3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833ac860251d5af2c71a70a8a65303e8634a934c6d3c5989d90bcd8b72883140"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('replication_ar2018': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
